{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom Improvised W2V Count1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiVoV5IFTSyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing all Libraries\n",
        "\n",
        "import re  # For preprocessing\n",
        "import pandas as pd  # For data handling\n",
        "from time import time  # To time our operations\n",
        "from collections import defaultdict  # For word frequency\n",
        "\n",
        "import spacy  # For preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import logging  # Setting up the loggings to monitor gensim\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_1LJAKWXmxk",
        "colab_type": "code",
        "outputId": "f7606866-854b-4bd7-ddb5-e6f323841542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Loading the dataset\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/fake.csv')\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12999, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msF72GV9dy8b",
        "colab_type": "code",
        "outputId": "5ba07362-4d08-4aa6-f2b6-ca7db9257f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>ord_in_thread</th>\n",
              "      <th>author</th>\n",
              "      <th>published</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>crawled</th>\n",
              "      <th>site_url</th>\n",
              "      <th>country</th>\n",
              "      <th>domain_rank</th>\n",
              "      <th>thread_title</th>\n",
              "      <th>spam_score</th>\n",
              "      <th>main_img_url</th>\n",
              "      <th>replies_count</th>\n",
              "      <th>participants_count</th>\n",
              "      <th>likes</th>\n",
              "      <th>comments</th>\n",
              "      <th>shares</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6a175f46bcd24d39b3e962ad0f29936721db70db</td>\n",
              "      <td>0</td>\n",
              "      <td>Barracuda Brigade</td>\n",
              "      <td>2016-10-26T21:41:00.000+03:00</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
              "      <td>Print They should pay all the back all the mon...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-27T01:49:27.168+03:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2bdc29d12605ef9cf3f09f9875040a7113be5d5b</td>\n",
              "      <td>0</td>\n",
              "      <td>reasoning with facts</td>\n",
              "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
              "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
              "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c70e149fdd53de5e61c29281100b9de0ed268bc3</td>\n",
              "      <td>0</td>\n",
              "      <td>Barracuda Brigade</td>\n",
              "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
              "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
              "      <td>Red State : \\nFox News Sunday reported this mo...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7cf7c15731ac2a116dd7f629bd57ea468ed70284</td>\n",
              "      <td>0</td>\n",
              "      <td>Fed Up</td>\n",
              "      <td>2016-11-01T05:22:00.000+02:00</td>\n",
              "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
              "      <td>Email Kayla Mueller was a prisoner and torture...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-11-01T15:46:26.304+02:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
              "      <td>0.068</td>\n",
              "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0206b54719c7e241ffe0ad4315b808290dbe6c0f</td>\n",
              "      <td>0</td>\n",
              "      <td>Fed Up</td>\n",
              "      <td>2016-11-01T21:56:00.000+02:00</td>\n",
              "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
              "      <td>Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-11-01T23:59:42.266+02:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
              "      <td>0.865</td>\n",
              "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       uuid  ord_in_thread  ... shares  type\n",
              "0  6a175f46bcd24d39b3e962ad0f29936721db70db              0  ...      0  bias\n",
              "1  2bdc29d12605ef9cf3f09f9875040a7113be5d5b              0  ...      0  bias\n",
              "2  c70e149fdd53de5e61c29281100b9de0ed268bc3              0  ...      0  bias\n",
              "3  7cf7c15731ac2a116dd7f629bd57ea468ed70284              0  ...      0  bias\n",
              "4  0206b54719c7e241ffe0ad4315b808290dbe6c0f              0  ...      0  bias\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrqDH7IY2ip_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data Pre-Processing(Treating Symbols and Stopwords Present in Data) using nltk and re\n",
        "\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]') #These Symbols will be replaced with Space\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')         #These Symbols will be Removed from Text\n",
        "STOPWORDS = set(stopwords.words('english')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxFr66Qn2l-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Text Cleaning Functions\n",
        "\n",
        "def string_form(value):\n",
        "    return str(value)\n",
        "\n",
        "def clean_text(text):\n",
        "   \n",
        "    text = BeautifulSoup(text, \"lxml\").text\n",
        "    text = text.lower()  #LowerCase Text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) #Replace Certain Symbols by Space in Text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) #Delete Certain Symbols from Text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) #Remove Stopwords from Text\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smodOObg2qS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Text Pre-processing and cleaning operations\n",
        "\n",
        "X_data = df['title'] + df['text']\n",
        "X_data = X_data.apply(string_form)\n",
        "X_data = X_data.apply(clean_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmagNjfU4OjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let us Remove all nan values\n",
        "\n",
        "X_data_final = []\n",
        "\n",
        "for e in range(len(X_data)):\n",
        "  if(X_data[e] != 'nan'):\n",
        "    X_data_final.append(X_data[e])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orBTYMJAnl8D",
        "colab_type": "code",
        "outputId": "013d8ecf-7712-4917-fe22-50f977a89ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X_data_final = np.array(X_data_final)\n",
        "X_data_final.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12273,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbUe1td6eRDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Further Cleaning Using Spacy\n",
        "\n",
        "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
        "\n",
        "def cleaning(doc):\n",
        "    # Lemmatizes and removes stopwords\n",
        "    # doc needs to be a spacy Doc object\n",
        "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
        "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
        "    # if a sentence is only one or two words long,\n",
        "    # the benefit for the training is very small\n",
        "    if len(txt) > 2:\n",
        "        return ' '.join(txt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U3Hnbkbea6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in X_data_final)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcV0_mHJelZM",
        "colab_type": "code",
        "outputId": "238cf372-159b-4b92-d776-cdc1f23f4f65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t = time()\n",
        "\n",
        "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\n",
        "\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to clean up everything: 3.38 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knFztIRweq4-",
        "colab_type": "code",
        "outputId": "50ba9ba6-cded-4481-f191-87e704a674cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_clean = pd.DataFrame({'clean': txt})\n",
        "df_clean = df_clean.dropna().drop_duplicates()\n",
        "df_clean.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12028, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0p15eusouLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we have 12028 samples meaning there's a good chance we will generate good useful vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QVZ4X4m2EXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models.phrases import Phrases, Phraser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVRtmDev2NNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent = [row.split() for row in df_clean['clean']]\n",
        "sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtnSBk7M2THh",
        "colab_type": "code",
        "outputId": "cfcf6226-d3b8-4251-cc61-03e61a929057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "phrases = Phrases(sent, min_count=30, progress_per=10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 09:52:31: collecting all words and their counts\n",
            "INFO - 09:52:31: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "INFO - 09:52:37: PROGRESS: at sentence #10000, processed 3447822 words and 1893403 word types\n",
            "INFO - 09:52:39: collected 2180496 word types from a corpus of 4146220 words (unigram + bigrams) and 12028 sentences\n",
            "INFO - 09:52:39: using 2180496 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyJCWI2k2s7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import bigrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4fRLNYU3n0s",
        "colab_type": "code",
        "outputId": "bee99870-09e2-4689-e53e-e1d16be8ac21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "sentences = phrases[sent]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0-ugxhN3gAl",
        "colab_type": "code",
        "outputId": "035195f6-3054-4c00-ccdd-eadeb9fd0296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "word_freq = defaultdict(int)\n",
        "for sent in sentences:\n",
        "    for i in sent:\n",
        "        word_freq[i] += 1\n",
        "len(word_freq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "158119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "415II7sqpaav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In the above Corpus we have 158,119 distinct words after cleaning from 171,533"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abrl7d_l4MPs",
        "colab_type": "code",
        "outputId": "652509ef-d586-431e-e527-7b483b974bb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Seeing the frequency of words(Top 10)\n",
        "\n",
        "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['not',\n",
              " 'say',\n",
              " 'people',\n",
              " 'trump',\n",
              " 'time',\n",
              " 'know',\n",
              " 's',\n",
              " 'clinton',\n",
              " 'like',\n",
              " 'state']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOM8RUYJ4Nke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import multiprocessing\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNVkyreA4RSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cores = multiprocessing.cpu_count() # Count the number of cores in a computer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdxoFqQx4YZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Word2vec model using Gensim(We can change min_count to any value for experimentation)\n",
        "# Size Denotes word-embedding vector Dimension which in out case is 100\n",
        "\n",
        "w2v_model = Word2Vec(min_count=1,\n",
        "                     window=3,\n",
        "                     size=100,\n",
        "                     sample=6e-5, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=cores-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjUMOLQM4bmW",
        "colab_type": "code",
        "outputId": "23f87c55-dc1f-4642-f5b1-7e8770ceb926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "t = time()\n",
        "\n",
        "w2v_model.build_vocab(sentences, progress_per=10000)\n",
        "\n",
        "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 09:53:24: collecting all words and their counts\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
            "INFO - 09:53:24: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 09:53:39: PROGRESS: at sentence #10000, processed 3231681 words, keeping 133846 word types\n",
            "INFO - 09:53:42: collected 158119 word types from a corpus of 3885672 raw words and 12028 sentences\n",
            "INFO - 09:53:42: Loading a fresh vocabulary\n",
            "INFO - 09:53:43: effective_min_count=1 retains 158119 unique words (100% of original 158119, drops 0)\n",
            "INFO - 09:53:43: effective_min_count=1 leaves 3885672 word corpus (100% of original 3885672, drops 0)\n",
            "INFO - 09:53:44: deleting the raw counts dictionary of 158119 items\n",
            "INFO - 09:53:44: sample=6e-05 downsamples 1183 most-common words\n",
            "INFO - 09:53:44: downsampling leaves estimated 2810286 word corpus (72.3% of prior 3885672)\n",
            "INFO - 09:53:44: estimated required memory for 158119 words and 100 dimensions: 205554700 bytes\n",
            "INFO - 09:53:44: resetting layer weights\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to build vocab: 0.85 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo_aKsmA4nz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building the word2vec model by training for 30 epochs\n",
        "\n",
        "t = time()\n",
        "\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
        "\n",
        "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mm8xo_Uazax",
        "colab_type": "code",
        "outputId": "72877c27-8e69-4fc9-b2dd-5214422c3bee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Save the model\n",
        "w2v_model.wv.save_word2vec_format('w2v_model.bin')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 10:05:31: storing 158119x100 projection weights into w2v_model.bin\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXzCEOKma65O",
        "colab_type": "code",
        "outputId": "b3d6dd4f-2452-4bcf-b1d0-e1304d7b4d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "w2v_model.wv.save_word2vec_format('w2v_model.txt', binary=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 10:05:44: storing 158119x100 projection weights into w2v_model.txt\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwi6Jm5JbUEx",
        "colab_type": "code",
        "outputId": "5845e0c7-0b20-4cda-fc25-f6df4d8fbc21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Total number of words vectorized\n",
        "# Notice that this number is large because we kept words with frequency 1\n",
        "words = list(w2v_model.wv.vocab)\n",
        "len(words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "158119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4ZSxP95ajtU",
        "colab_type": "text"
      },
      "source": [
        "# Most Similar Word Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngWYDz9o76CD",
        "colab_type": "code",
        "outputId": "5f86026c-902b-44ab-99a6-15a8655cde59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"fake\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 10:06:18: precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('id', 0.5883486270904541),\n",
              " ('ids', 0.5781641006469727),\n",
              " ('hoax', 0.5745216608047485),\n",
              " ('fabricate', 0.5445030927658081),\n",
              " ('whopper', 0.522573709487915),\n",
              " ('false_narrative', 0.519706666469574),\n",
              " ('false', 0.5131078958511353),\n",
              " ('crisis_actor', 0.4988062381744385),\n",
              " ('bogus', 0.4836941957473755),\n",
              " ('fake_news', 0.4749912619590759)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhDBFwCQ8GOQ",
        "colab_type": "code",
        "outputId": "faaa6b35-a22a-4aa1-b07b-b40ed29a9cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"freedom\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('liberty', 0.6756128072738647),\n",
              " ('democracy', 0.631916880607605),\n",
              " ('cherish', 0.60960853099823),\n",
              " ('freedom_speech', 0.5919955968856812),\n",
              " ('freedom_expression', 0.5844323635101318),\n",
              " ('right', 0.573498010635376),\n",
              " ('semblance', 0.5713706016540527),\n",
              " ('dignity', 0.5597898960113525),\n",
              " ('respect', 0.5502725839614868),\n",
              " ('prosperity', 0.5439368486404419)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4rL20molLa_",
        "colab_type": "code",
        "outputId": "399d7c40-d543-4a33-bdab-9e46df3e665f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"attack\"],topn=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('target', 0.6575837731361389),\n",
              " ('assault', 0.6551152467727661),\n",
              " ('terrorist_attack', 0.6341935396194458),\n",
              " ('claim', 0.6250004768371582),\n",
              " ('strike', 0.6227885484695435),\n",
              " ('kill', 0.5861219763755798),\n",
              " ('indiscriminate', 0.5814937353134155),\n",
              " ('force', 0.5803516507148743),\n",
              " ('launch', 0.5773041844367981),\n",
              " ('killing', 0.5768757462501526)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my4owghFlYGY",
        "colab_type": "code",
        "outputId": "b942c607-f483-46dc-d9ab-573b48de3072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"bomb\"],topn=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('detonate', 0.6688288450241089),\n",
              " ('bombing', 0.6180896759033203),\n",
              " ('munition', 0.5712682008743286),\n",
              " ('bombardment', 0.5458507537841797),\n",
              " ('civilian', 0.5426082611083984),\n",
              " ('attack', 0.5399023294448853),\n",
              " ('gingerly', 0.5328900814056396),\n",
              " ('atomic_bomb', 0.5309829711914062),\n",
              " ('governmentsnot', 0.5238995552062988),\n",
              " ('neardefenseless', 0.5224360227584839)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n__NsgvzlwYM",
        "colab_type": "code",
        "outputId": "551de08f-39cc-4135-906f-3c218d445b95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"president\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('elect', 0.7453252077102661),\n",
              " ('obama', 0.7041237354278564),\n",
              " ('white_house', 0.6970391273498535),\n",
              " ('presidency', 0.6857277154922485),\n",
              " ('trump', 0.6828287243843079),\n",
              " ('administration', 0.6744243502616882),\n",
              " ('elect_president', 0.6497210264205933),\n",
              " ('hillary_clinton', 0.6286641955375671),\n",
              " ('office', 0.6267598867416382),\n",
              " ('presidentelect_trump', 0.6243784427642822)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22S6-D63l5VD",
        "colab_type": "code",
        "outputId": "40f86995-2029-47f1-9ea4-620ed4880ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"terror\"],topn=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('terrorism', 0.6181561946868896),\n",
              " ('terrorist', 0.6153697967529297),\n",
              " ('islamism', 0.5353000164031982),\n",
              " ('kla', 0.5323553681373596),\n",
              " ('extremism', 0.5294589996337891),\n",
              " ('terror_group', 0.529383659362793),\n",
              " ('terror_attack', 0.5037004351615906),\n",
              " ('islamic', 0.4970577657222748),\n",
              " ('jihadist', 0.4927752912044525),\n",
              " ('terrorist_attack', 0.4899193346500397)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4f71VS5e62e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can see from above that word vector learnt are good estimates for understanding relation between words"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}