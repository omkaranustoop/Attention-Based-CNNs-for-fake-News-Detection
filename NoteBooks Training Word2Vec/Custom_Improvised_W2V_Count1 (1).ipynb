{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom Improvised W2V Count1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiVoV5IFTSyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing all Libraries\n",
        "\n",
        "import re  # For preprocessing\n",
        "import pandas as pd  # For data handling\n",
        "from time import time  # To time our operations\n",
        "from collections import defaultdict  # For word frequency\n",
        "\n",
        "import spacy  # For preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import logging  # Setting up the loggings to monitor gensim\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_1LJAKWXmxk",
        "colab_type": "code",
        "outputId": "f7606866-854b-4bd7-ddb5-e6f323841542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Loading the dataset\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/fake.csv')\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12999, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msF72GV9dy8b",
        "colab_type": "code",
        "outputId": "5ba07362-4d08-4aa6-f2b6-ca7db9257f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>ord_in_thread</th>\n",
              "      <th>author</th>\n",
              "      <th>published</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>crawled</th>\n",
              "      <th>site_url</th>\n",
              "      <th>country</th>\n",
              "      <th>domain_rank</th>\n",
              "      <th>thread_title</th>\n",
              "      <th>spam_score</th>\n",
              "      <th>main_img_url</th>\n",
              "      <th>replies_count</th>\n",
              "      <th>participants_count</th>\n",
              "      <th>likes</th>\n",
              "      <th>comments</th>\n",
              "      <th>shares</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6a175f46bcd24d39b3e962ad0f29936721db70db</td>\n",
              "      <td>0</td>\n",
              "      <td>Barracuda Brigade</td>\n",
              "      <td>2016-10-26T21:41:00.000+03:00</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
              "      <td>Print They should pay all the back all the mon...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-27T01:49:27.168+03:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2bdc29d12605ef9cf3f09f9875040a7113be5d5b</td>\n",
              "      <td>0</td>\n",
              "      <td>reasoning with facts</td>\n",
              "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
              "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
              "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c70e149fdd53de5e61c29281100b9de0ed268bc3</td>\n",
              "      <td>0</td>\n",
              "      <td>Barracuda Brigade</td>\n",
              "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
              "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
              "      <td>Red State : \\nFox News Sunday reported this mo...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7cf7c15731ac2a116dd7f629bd57ea468ed70284</td>\n",
              "      <td>0</td>\n",
              "      <td>Fed Up</td>\n",
              "      <td>2016-11-01T05:22:00.000+02:00</td>\n",
              "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
              "      <td>Email Kayla Mueller was a prisoner and torture...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-11-01T15:46:26.304+02:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
              "      <td>0.068</td>\n",
              "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0206b54719c7e241ffe0ad4315b808290dbe6c0f</td>\n",
              "      <td>0</td>\n",
              "      <td>Fed Up</td>\n",
              "      <td>2016-11-01T21:56:00.000+02:00</td>\n",
              "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
              "      <td>Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-11-01T23:59:42.266+02:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
              "      <td>0.865</td>\n",
              "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       uuid  ord_in_thread  ... shares  type\n",
              "0  6a175f46bcd24d39b3e962ad0f29936721db70db              0  ...      0  bias\n",
              "1  2bdc29d12605ef9cf3f09f9875040a7113be5d5b              0  ...      0  bias\n",
              "2  c70e149fdd53de5e61c29281100b9de0ed268bc3              0  ...      0  bias\n",
              "3  7cf7c15731ac2a116dd7f629bd57ea468ed70284              0  ...      0  bias\n",
              "4  0206b54719c7e241ffe0ad4315b808290dbe6c0f              0  ...      0  bias\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrqDH7IY2ip_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data Pre-Processing(Treating Symbols and Stopwords Present in Data) using nltk and re\n",
        "\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]') #These Symbols will be replaced with Space\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')         #These Symbols will be Removed from Text\n",
        "STOPWORDS = set(stopwords.words('english')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxFr66Qn2l-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Text Cleaning Functions\n",
        "\n",
        "def string_form(value):\n",
        "    return str(value)\n",
        "\n",
        "def clean_text(text):\n",
        "   \n",
        "    text = BeautifulSoup(text, \"lxml\").text\n",
        "    text = text.lower()  #LowerCase Text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) #Replace Certain Symbols by Space in Text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) #Delete Certain Symbols from Text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) #Remove Stopwords from Text\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smodOObg2qS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Text Pre-processing and cleaning operations\n",
        "\n",
        "X_data = df['title'] + df['text']\n",
        "X_data = X_data.apply(string_form)\n",
        "X_data = X_data.apply(clean_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmagNjfU4OjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let us Remove all nan values\n",
        "\n",
        "X_data_final = []\n",
        "\n",
        "for e in range(len(X_data)):\n",
        "  if(X_data[e] != 'nan'):\n",
        "    X_data_final.append(X_data[e])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orBTYMJAnl8D",
        "colab_type": "code",
        "outputId": "013d8ecf-7712-4917-fe22-50f977a89ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X_data_final = np.array(X_data_final)\n",
        "X_data_final.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12273,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbUe1td6eRDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Further Cleaning Using Spacy\n",
        "\n",
        "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
        "\n",
        "def cleaning(doc):\n",
        "    # Lemmatizes and removes stopwords\n",
        "    # doc needs to be a spacy Doc object\n",
        "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
        "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
        "    # if a sentence is only one or two words long,\n",
        "    # the benefit for the training is very small\n",
        "    if len(txt) > 2:\n",
        "        return ' '.join(txt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U3Hnbkbea6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in X_data_final)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcV0_mHJelZM",
        "colab_type": "code",
        "outputId": "238cf372-159b-4b92-d776-cdc1f23f4f65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t = time()\n",
        "\n",
        "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\n",
        "\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to clean up everything: 3.38 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knFztIRweq4-",
        "colab_type": "code",
        "outputId": "50ba9ba6-cded-4481-f191-87e704a674cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_clean = pd.DataFrame({'clean': txt})\n",
        "df_clean = df_clean.dropna().drop_duplicates()\n",
        "df_clean.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12028, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0p15eusouLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we have 12028 samples meaning there's a good chance we will generate good useful vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QVZ4X4m2EXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models.phrases import Phrases, Phraser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVRtmDev2NNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent = [row.split() for row in df_clean['clean']]\n",
        "sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtnSBk7M2THh",
        "colab_type": "code",
        "outputId": "cfcf6226-d3b8-4251-cc61-03e61a929057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "phrases = Phrases(sent, min_count=30, progress_per=10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 09:52:31: collecting all words and their counts\n",
            "INFO - 09:52:31: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "INFO - 09:52:37: PROGRESS: at sentence #10000, processed 3447822 words and 1893403 word types\n",
            "INFO - 09:52:39: collected 2180496 word types from a corpus of 4146220 words (unigram + bigrams) and 12028 sentences\n",
            "INFO - 09:52:39: using 2180496 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyJCWI2k2s7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import bigrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4fRLNYU3n0s",
        "colab_type": "code",
        "outputId": "bee99870-09e2-4689-e53e-e1d16be8ac21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "sentences = phrases[sent]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0-ugxhN3gAl",
        "colab_type": "code",
        "outputId": "035195f6-3054-4c00-ccdd-eadeb9fd0296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "word_freq = defaultdict(int)\n",
        "for sent in sentences:\n",
        "    for i in sent:\n",
        "        word_freq[i] += 1\n",
        "len(word_freq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "158119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "415II7sqpaav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In the above Corpus we have 158,119 distinct words after cleaning from 171,533"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abrl7d_l4MPs",
        "colab_type": "code",
        "outputId": "652509ef-d586-431e-e527-7b483b974bb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Seeing the frequency of words(Top 10)\n",
        "\n",
        "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['not',\n",
              " 'say',\n",
              " 'people',\n",
              " 'trump',\n",
              " 'time',\n",
              " 'know',\n",
              " 's',\n",
              " 'clinton',\n",
              " 'like',\n",
              " 'state']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOM8RUYJ4Nke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import multiprocessing\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNVkyreA4RSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cores = multiprocessing.cpu_count() # Count the number of cores in a computer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdxoFqQx4YZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Word2vec model using Gensim(We can change min_count to any value for experimentation)\n",
        "# Size Denotes word-embedding vector Dimension which in out case is 100\n",
        "\n",
        "w2v_model = Word2Vec(min_count=1,\n",
        "                     window=3,\n",
        "                     size=100,\n",
        "                     sample=6e-5, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=cores-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjUMOLQM4bmW",
        "colab_type": "code",
        "outputId": "23f87c55-dc1f-4642-f5b1-7e8770ceb926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "t = time()\n",
        "\n",
        "w2v_model.build_vocab(sentences, progress_per=10000)\n",
        "\n",
        "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 09:53:24: collecting all words and their counts\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
            "INFO - 09:53:24: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 09:53:39: PROGRESS: at sentence #10000, processed 3231681 words, keeping 133846 word types\n",
            "INFO - 09:53:42: collected 158119 word types from a corpus of 3885672 raw words and 12028 sentences\n",
            "INFO - 09:53:42: Loading a fresh vocabulary\n",
            "INFO - 09:53:43: effective_min_count=1 retains 158119 unique words (100% of original 158119, drops 0)\n",
            "INFO - 09:53:43: effective_min_count=1 leaves 3885672 word corpus (100% of original 3885672, drops 0)\n",
            "INFO - 09:53:44: deleting the raw counts dictionary of 158119 items\n",
            "INFO - 09:53:44: sample=6e-05 downsamples 1183 most-common words\n",
            "INFO - 09:53:44: downsampling leaves estimated 2810286 word corpus (72.3% of prior 3885672)\n",
            "INFO - 09:53:44: estimated required memory for 158119 words and 100 dimensions: 205554700 bytes\n",
            "INFO - 09:53:44: resetting layer weights\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to build vocab: 0.85 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo_aKsmA4nz_",
        "colab_type": "code",
        "outputId": "8e5b631c-5e96-47d8-98ca-734d48267a24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Building the word2vec model by training for 30 epochs\n",
        "\n",
        "t = time()\n",
        "\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
        "\n",
        "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 09:54:22: training model with 3 workers on 158119 vocabulary and 100 features, using sg=0 hs=0 sample=6e-05 negative=20 window=3\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
            "INFO - 09:54:23: EPOCH 1 - PROGRESS: at 5.65% examples, 119722 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:24: EPOCH 1 - PROGRESS: at 10.70% examples, 125377 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:25: EPOCH 1 - PROGRESS: at 14.10% examples, 126250 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:27: EPOCH 1 - PROGRESS: at 20.95% examples, 127920 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:28: EPOCH 1 - PROGRESS: at 25.89% examples, 127395 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:29: EPOCH 1 - PROGRESS: at 30.68% examples, 127427 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:30: EPOCH 1 - PROGRESS: at 33.71% examples, 127208 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:31: EPOCH 1 - PROGRESS: at 38.45% examples, 126634 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:32: EPOCH 1 - PROGRESS: at 44.43% examples, 126799 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:33: EPOCH 1 - PROGRESS: at 49.03% examples, 126297 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:34: EPOCH 1 - PROGRESS: at 55.45% examples, 126535 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:35: EPOCH 1 - PROGRESS: at 61.34% examples, 126817 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:36: EPOCH 1 - PROGRESS: at 65.42% examples, 126742 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:37: EPOCH 1 - PROGRESS: at 69.50% examples, 127068 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:38: EPOCH 1 - PROGRESS: at 73.54% examples, 126632 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:39: EPOCH 1 - PROGRESS: at 76.06% examples, 126805 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:40: EPOCH 1 - PROGRESS: at 79.99% examples, 127088 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:41: EPOCH 1 - PROGRESS: at 84.05% examples, 126830 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:42: EPOCH 1 - PROGRESS: at 89.87% examples, 126622 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:43: EPOCH 1 - PROGRESS: at 93.50% examples, 126923 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:44: EPOCH 1 - PROGRESS: at 97.24% examples, 126868 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:45: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 09:54:45: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 09:54:45: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 09:54:45: EPOCH - 1 : training on 3885672 raw words (2809062 effective words) took 22.1s, 126926 effective words/s\n",
            "INFO - 09:54:46: EPOCH 2 - PROGRESS: at 5.89% examples, 125310 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:47: EPOCH 2 - PROGRESS: at 10.70% examples, 124657 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:48: EPOCH 2 - PROGRESS: at 14.10% examples, 126005 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:49: EPOCH 2 - PROGRESS: at 20.95% examples, 127860 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:50: EPOCH 2 - PROGRESS: at 25.89% examples, 127293 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:51: EPOCH 2 - PROGRESS: at 30.68% examples, 128034 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:52: EPOCH 2 - PROGRESS: at 33.34% examples, 127532 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:53: EPOCH 2 - PROGRESS: at 38.61% examples, 127799 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:54: EPOCH 2 - PROGRESS: at 44.96% examples, 127816 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:55: EPOCH 2 - PROGRESS: at 49.26% examples, 127655 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:56: EPOCH 2 - PROGRESS: at 55.84% examples, 127705 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:57: EPOCH 2 - PROGRESS: at 61.47% examples, 128244 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:58: EPOCH 2 - PROGRESS: at 65.61% examples, 127882 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:54:59: EPOCH 2 - PROGRESS: at 69.60% examples, 128087 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:00: EPOCH 2 - PROGRESS: at 73.55% examples, 127755 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:01: EPOCH 2 - PROGRESS: at 76.22% examples, 127643 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:02: EPOCH 2 - PROGRESS: at 79.64% examples, 127220 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:03: EPOCH 2 - PROGRESS: at 83.83% examples, 126967 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:04: EPOCH 2 - PROGRESS: at 89.76% examples, 126831 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:05: EPOCH 2 - PROGRESS: at 93.50% examples, 127177 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:06: EPOCH 2 - PROGRESS: at 97.24% examples, 127334 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:07: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 09:55:07: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 09:55:07: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 09:55:07: EPOCH - 2 : training on 3885672 raw words (2810523 effective words) took 22.0s, 127625 effective words/s\n",
            "INFO - 09:55:08: EPOCH 3 - PROGRESS: at 5.65% examples, 118431 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:09: EPOCH 3 - PROGRESS: at 10.84% examples, 126328 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:10: EPOCH 3 - PROGRESS: at 15.01% examples, 127245 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:11: EPOCH 3 - PROGRESS: at 21.06% examples, 128690 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:12: EPOCH 3 - PROGRESS: at 26.36% examples, 128535 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:13: EPOCH 3 - PROGRESS: at 30.92% examples, 128384 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:14: EPOCH 3 - PROGRESS: at 35.21% examples, 128442 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:15: EPOCH 3 - PROGRESS: at 40.11% examples, 127999 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:16: EPOCH 3 - PROGRESS: at 45.89% examples, 127970 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:17: EPOCH 3 - PROGRESS: at 51.01% examples, 127736 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:18: EPOCH 3 - PROGRESS: at 57.75% examples, 128029 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:19: EPOCH 3 - PROGRESS: at 62.47% examples, 128268 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:20: EPOCH 3 - PROGRESS: at 66.50% examples, 128336 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:21: EPOCH 3 - PROGRESS: at 70.28% examples, 128147 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:22: EPOCH 3 - PROGRESS: at 73.63% examples, 127462 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:23: EPOCH 3 - PROGRESS: at 76.70% examples, 127131 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:24: EPOCH 3 - PROGRESS: at 80.42% examples, 127114 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:25: EPOCH 3 - PROGRESS: at 84.64% examples, 126985 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:26: EPOCH 3 - PROGRESS: at 90.17% examples, 126682 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:27: EPOCH 3 - PROGRESS: at 93.81% examples, 127068 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 09:55:28: EPOCH 3 - PROGRESS: at 97.94% examples, 127354 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:29: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 09:55:29: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 09:55:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 09:55:29: EPOCH - 3 : training on 3885672 raw words (2809642 effective words) took 22.1s, 127357 effective words/s\n",
            "INFO - 09:55:30: EPOCH 4 - PROGRESS: at 5.89% examples, 127406 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:31: EPOCH 4 - PROGRESS: at 10.97% examples, 130959 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:32: EPOCH 4 - PROGRESS: at 15.01% examples, 130001 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:33: EPOCH 4 - PROGRESS: at 21.06% examples, 130714 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:34: EPOCH 4 - PROGRESS: at 26.65% examples, 130765 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:35: EPOCH 4 - PROGRESS: at 31.00% examples, 130753 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:36: EPOCH 4 - PROGRESS: at 35.21% examples, 130175 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:37: EPOCH 4 - PROGRESS: at 40.11% examples, 129524 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:38: EPOCH 4 - PROGRESS: at 45.62% examples, 128434 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:39: EPOCH 4 - PROGRESS: at 49.52% examples, 127969 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:40: EPOCH 4 - PROGRESS: at 56.48% examples, 127758 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:41: EPOCH 4 - PROGRESS: at 61.47% examples, 127763 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:42: EPOCH 4 - PROGRESS: at 65.42% examples, 127427 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:43: EPOCH 4 - PROGRESS: at 69.33% examples, 127439 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:44: EPOCH 4 - PROGRESS: at 73.52% examples, 126917 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:45: EPOCH 4 - PROGRESS: at 75.86% examples, 126633 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:46: EPOCH 4 - PROGRESS: at 78.69% examples, 126539 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:47: EPOCH 4 - PROGRESS: at 83.51% examples, 126413 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:48: EPOCH 4 - PROGRESS: at 89.63% examples, 126344 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:49: EPOCH 4 - PROGRESS: at 93.35% examples, 126388 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:50: EPOCH 4 - PROGRESS: at 96.96% examples, 126843 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:51: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 09:55:51: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 09:55:51: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 09:55:51: EPOCH - 4 : training on 3885672 raw words (2809937 effective words) took 22.1s, 126968 effective words/s\n",
            "INFO - 09:55:52: EPOCH 5 - PROGRESS: at 5.89% examples, 125096 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:53: EPOCH 5 - PROGRESS: at 10.84% examples, 127189 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:54: EPOCH 5 - PROGRESS: at 14.47% examples, 126840 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:55: EPOCH 5 - PROGRESS: at 21.00% examples, 129243 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:56: EPOCH 5 - PROGRESS: at 26.10% examples, 128848 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:57: EPOCH 5 - PROGRESS: at 30.80% examples, 129338 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:58: EPOCH 5 - PROGRESS: at 34.19% examples, 129124 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:55:59: EPOCH 5 - PROGRESS: at 38.61% examples, 128359 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:00: EPOCH 5 - PROGRESS: at 44.43% examples, 127779 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:01: EPOCH 5 - PROGRESS: at 49.03% examples, 127607 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:02: EPOCH 5 - PROGRESS: at 55.45% examples, 127482 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:03: EPOCH 5 - PROGRESS: at 61.22% examples, 127653 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:04: EPOCH 5 - PROGRESS: at 65.13% examples, 127559 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:05: EPOCH 5 - PROGRESS: at 68.93% examples, 127290 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:06: EPOCH 5 - PROGRESS: at 73.52% examples, 127255 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:07: EPOCH 5 - PROGRESS: at 75.86% examples, 127008 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:08: EPOCH 5 - PROGRESS: at 78.69% examples, 126718 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:09: EPOCH 5 - PROGRESS: at 83.51% examples, 126657 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:10: EPOCH 5 - PROGRESS: at 89.76% examples, 126653 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:11: EPOCH 5 - PROGRESS: at 93.44% examples, 126774 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:12: EPOCH 5 - PROGRESS: at 97.24% examples, 127089 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:13: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 09:56:13: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 09:56:13: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 09:56:13: EPOCH - 5 : training on 3885672 raw words (2809823 effective words) took 22.1s, 127316 effective words/s\n",
            "INFO - 09:56:14: EPOCH 6 - PROGRESS: at 5.65% examples, 122606 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:15: EPOCH 6 - PROGRESS: at 10.84% examples, 128622 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:16: EPOCH 6 - PROGRESS: at 15.01% examples, 130092 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:17: EPOCH 6 - PROGRESS: at 21.06% examples, 131550 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:18: EPOCH 6 - PROGRESS: at 26.36% examples, 131301 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:19: EPOCH 6 - PROGRESS: at 30.92% examples, 130606 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:20: EPOCH 6 - PROGRESS: at 34.74% examples, 129790 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:21: EPOCH 6 - PROGRESS: at 39.49% examples, 129528 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:22: EPOCH 6 - PROGRESS: at 45.28% examples, 128747 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:23: EPOCH 6 - PROGRESS: at 49.52% examples, 128152 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:24: EPOCH 6 - PROGRESS: at 56.48% examples, 128292 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:25: EPOCH 6 - PROGRESS: at 61.47% examples, 128571 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:26: EPOCH 6 - PROGRESS: at 65.61% examples, 128428 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:27: EPOCH 6 - PROGRESS: at 69.60% examples, 128439 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:28: EPOCH 6 - PROGRESS: at 73.55% examples, 127925 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:29: EPOCH 6 - PROGRESS: at 76.22% examples, 127965 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:30: EPOCH 6 - PROGRESS: at 79.99% examples, 127819 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:31: EPOCH 6 - PROGRESS: at 84.34% examples, 127895 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:32: EPOCH 6 - PROGRESS: at 90.01% examples, 127467 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:33: EPOCH 6 - PROGRESS: at 93.63% examples, 127788 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:34: EPOCH 6 - PROGRESS: at 97.53% examples, 127854 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:35: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 09:56:35: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 09:56:35: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 09:56:35: EPOCH - 6 : training on 3885672 raw words (2810011 effective words) took 22.0s, 127954 effective words/s\n",
            "INFO - 09:56:36: EPOCH 7 - PROGRESS: at 5.89% examples, 127192 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:37: EPOCH 7 - PROGRESS: at 10.84% examples, 129149 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:38: EPOCH 7 - PROGRESS: at 14.47% examples, 128439 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:39: EPOCH 7 - PROGRESS: at 20.95% examples, 128912 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:40: EPOCH 7 - PROGRESS: at 25.89% examples, 128244 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:41: EPOCH 7 - PROGRESS: at 30.68% examples, 128713 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:42: EPOCH 7 - PROGRESS: at 34.19% examples, 129346 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:43: EPOCH 7 - PROGRESS: at 38.98% examples, 128942 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:44: EPOCH 7 - PROGRESS: at 45.28% examples, 128547 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:45: EPOCH 7 - PROGRESS: at 49.52% examples, 128698 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:46: EPOCH 7 - PROGRESS: at 56.48% examples, 128658 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:47: EPOCH 7 - PROGRESS: at 61.47% examples, 128920 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:48: EPOCH 7 - PROGRESS: at 65.61% examples, 128650 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:49: EPOCH 7 - PROGRESS: at 69.60% examples, 128963 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:50: EPOCH 7 - PROGRESS: at 73.55% examples, 128214 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:51: EPOCH 7 - PROGRESS: at 76.46% examples, 128295 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:52: EPOCH 7 - PROGRESS: at 80.21% examples, 128415 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:53: EPOCH 7 - PROGRESS: at 84.64% examples, 128093 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:54: EPOCH 7 - PROGRESS: at 90.17% examples, 127793 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:55: EPOCH 7 - PROGRESS: at 93.91% examples, 128492 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:56: EPOCH 7 - PROGRESS: at 98.33% examples, 128668 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:57: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 09:56:57: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 09:56:57: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 09:56:57: EPOCH - 7 : training on 3885672 raw words (2810734 effective words) took 21.8s, 128763 effective words/s\n",
            "INFO - 09:56:58: EPOCH 8 - PROGRESS: at 5.65% examples, 121607 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:56:59: EPOCH 8 - PROGRESS: at 10.84% examples, 128969 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:00: EPOCH 8 - PROGRESS: at 14.47% examples, 128281 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:01: EPOCH 8 - PROGRESS: at 21.00% examples, 130441 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:02: EPOCH 8 - PROGRESS: at 26.10% examples, 130061 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:03: EPOCH 8 - PROGRESS: at 30.80% examples, 129493 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:04: EPOCH 8 - PROGRESS: at 34.74% examples, 129970 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:05: EPOCH 8 - PROGRESS: at 38.98% examples, 128952 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:06: EPOCH 8 - PROGRESS: at 45.62% examples, 129233 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:07: EPOCH 8 - PROGRESS: at 50.39% examples, 128740 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:08: EPOCH 8 - PROGRESS: at 56.81% examples, 128350 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:09: EPOCH 8 - PROGRESS: at 62.17% examples, 128654 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:10: EPOCH 8 - PROGRESS: at 66.00% examples, 128365 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:11: EPOCH 8 - PROGRESS: at 70.04% examples, 128388 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:12: EPOCH 8 - PROGRESS: at 73.61% examples, 127777 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:13: EPOCH 8 - PROGRESS: at 76.46% examples, 127295 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:14: EPOCH 8 - PROGRESS: at 80.21% examples, 127179 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:15: EPOCH 8 - PROGRESS: at 84.34% examples, 126926 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:16: EPOCH 8 - PROGRESS: at 90.17% examples, 126733 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:17: EPOCH 8 - PROGRESS: at 93.81% examples, 126958 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:18: EPOCH 8 - PROGRESS: at 97.94% examples, 127095 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:19: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 09:57:19: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 09:57:19: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 09:57:19: EPOCH - 8 : training on 3885672 raw words (2810595 effective words) took 22.1s, 127321 effective words/s\n",
            "INFO - 09:57:20: EPOCH 9 - PROGRESS: at 5.65% examples, 122137 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:21: EPOCH 9 - PROGRESS: at 10.70% examples, 126653 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:22: EPOCH 9 - PROGRESS: at 14.10% examples, 126830 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 09:57:23: EPOCH 9 - PROGRESS: at 21.00% examples, 129803 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:24: EPOCH 9 - PROGRESS: at 26.10% examples, 129345 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:25: EPOCH 9 - PROGRESS: at 30.80% examples, 128840 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:26: EPOCH 9 - PROGRESS: at 33.71% examples, 128217 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:27: EPOCH 9 - PROGRESS: at 38.45% examples, 127490 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:28: EPOCH 9 - PROGRESS: at 44.43% examples, 127601 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:29: EPOCH 9 - PROGRESS: at 49.03% examples, 127136 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:30: EPOCH 9 - PROGRESS: at 55.45% examples, 127104 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:31: EPOCH 9 - PROGRESS: at 61.22% examples, 127347 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:32: EPOCH 9 - PROGRESS: at 65.26% examples, 127480 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:33: EPOCH 9 - PROGRESS: at 68.93% examples, 127255 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:34: EPOCH 9 - PROGRESS: at 73.52% examples, 127103 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:35: EPOCH 9 - PROGRESS: at 75.86% examples, 127018 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:36: EPOCH 9 - PROGRESS: at 78.69% examples, 126789 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:37: EPOCH 9 - PROGRESS: at 83.51% examples, 126850 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:38: EPOCH 9 - PROGRESS: at 89.63% examples, 126689 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:39: EPOCH 9 - PROGRESS: at 93.35% examples, 126845 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:40: EPOCH 9 - PROGRESS: at 96.96% examples, 127056 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:41: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 09:57:41: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 09:57:41: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 09:57:41: EPOCH - 9 : training on 3885672 raw words (2810704 effective words) took 22.1s, 127245 effective words/s\n",
            "INFO - 09:57:42: EPOCH 10 - PROGRESS: at 5.89% examples, 121725 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:43: EPOCH 10 - PROGRESS: at 10.97% examples, 125100 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:44: EPOCH 10 - PROGRESS: at 15.01% examples, 126421 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:45: EPOCH 10 - PROGRESS: at 21.06% examples, 127935 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:46: EPOCH 10 - PROGRESS: at 26.36% examples, 127989 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:47: EPOCH 10 - PROGRESS: at 30.92% examples, 128055 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:48: EPOCH 10 - PROGRESS: at 34.19% examples, 127218 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:49: EPOCH 10 - PROGRESS: at 39.49% examples, 128195 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:50: EPOCH 10 - PROGRESS: at 45.62% examples, 128048 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:51: EPOCH 10 - PROGRESS: at 50.39% examples, 128083 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:52: EPOCH 10 - PROGRESS: at 56.81% examples, 127878 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:53: EPOCH 10 - PROGRESS: at 62.17% examples, 128415 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:54: EPOCH 10 - PROGRESS: at 66.00% examples, 128117 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:55: EPOCH 10 - PROGRESS: at 70.04% examples, 128243 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:56: EPOCH 10 - PROGRESS: at 73.60% examples, 127752 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:57: EPOCH 10 - PROGRESS: at 76.70% examples, 127642 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:58: EPOCH 10 - PROGRESS: at 80.42% examples, 127688 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:57:59: EPOCH 10 - PROGRESS: at 84.64% examples, 127303 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:00: EPOCH 10 - PROGRESS: at 90.75% examples, 127389 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:02: EPOCH 10 - PROGRESS: at 93.91% examples, 127637 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:03: EPOCH 10 - PROGRESS: at 97.94% examples, 127608 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:03: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 09:58:03: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 09:58:03: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 09:58:03: EPOCH - 10 : training on 3885672 raw words (2810751 effective words) took 22.0s, 127690 effective words/s\n",
            "INFO - 09:58:04: EPOCH 11 - PROGRESS: at 5.89% examples, 123246 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:05: EPOCH 11 - PROGRESS: at 10.84% examples, 126705 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:06: EPOCH 11 - PROGRESS: at 14.47% examples, 125030 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:07: EPOCH 11 - PROGRESS: at 21.06% examples, 128102 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:08: EPOCH 11 - PROGRESS: at 26.36% examples, 127441 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:09: EPOCH 11 - PROGRESS: at 31.00% examples, 128461 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:10: EPOCH 11 - PROGRESS: at 35.21% examples, 128461 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:11: EPOCH 11 - PROGRESS: at 40.11% examples, 127858 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:12: EPOCH 11 - PROGRESS: at 45.89% examples, 127489 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:13: EPOCH 11 - PROGRESS: at 50.39% examples, 127275 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:14: EPOCH 11 - PROGRESS: at 56.81% examples, 127215 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:15: EPOCH 11 - PROGRESS: at 61.74% examples, 127119 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:16: EPOCH 11 - PROGRESS: at 65.90% examples, 127048 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:17: EPOCH 11 - PROGRESS: at 69.74% examples, 127442 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:18: EPOCH 11 - PROGRESS: at 73.61% examples, 127552 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:19: EPOCH 11 - PROGRESS: at 76.85% examples, 127623 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:21: EPOCH 11 - PROGRESS: at 80.64% examples, 127440 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:22: EPOCH 11 - PROGRESS: at 85.94% examples, 127389 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:23: EPOCH 11 - PROGRESS: at 91.71% examples, 127362 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:24: EPOCH 11 - PROGRESS: at 94.04% examples, 127331 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:25: EPOCH 11 - PROGRESS: at 98.33% examples, 127246 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:25: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 09:58:25: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 09:58:25: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 09:58:25: EPOCH - 11 : training on 3885672 raw words (2810033 effective words) took 22.0s, 127524 effective words/s\n",
            "INFO - 09:58:26: EPOCH 12 - PROGRESS: at 5.65% examples, 118991 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:27: EPOCH 12 - PROGRESS: at 10.70% examples, 124127 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:28: EPOCH 12 - PROGRESS: at 14.10% examples, 125417 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:29: EPOCH 12 - PROGRESS: at 20.89% examples, 125909 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:30: EPOCH 12 - PROGRESS: at 25.39% examples, 124239 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:31: EPOCH 12 - PROGRESS: at 28.53% examples, 118953 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:32: EPOCH 12 - PROGRESS: at 32.16% examples, 118329 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:33: EPOCH 12 - PROGRESS: at 36.56% examples, 119627 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:34: EPOCH 12 - PROGRESS: at 41.84% examples, 120435 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:35: EPOCH 12 - PROGRESS: at 47.16% examples, 120686 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:36: EPOCH 12 - PROGRESS: at 52.78% examples, 121199 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:37: EPOCH 12 - PROGRESS: at 59.79% examples, 122144 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:38: EPOCH 12 - PROGRESS: at 64.15% examples, 122882 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:39: EPOCH 12 - PROGRESS: at 67.86% examples, 123210 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:40: EPOCH 12 - PROGRESS: at 73.19% examples, 123688 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:41: EPOCH 12 - PROGRESS: at 75.08% examples, 123541 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:42: EPOCH 12 - PROGRESS: at 78.49% examples, 123524 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:44: EPOCH 12 - PROGRESS: at 82.48% examples, 123872 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:45: EPOCH 12 - PROGRESS: at 88.78% examples, 124066 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:46: EPOCH 12 - PROGRESS: at 92.82% examples, 124143 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:47: EPOCH 12 - PROGRESS: at 95.68% examples, 124637 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:47: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 09:58:47: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 09:58:47: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 09:58:47: EPOCH - 12 : training on 3885672 raw words (2809481 effective words) took 22.5s, 124820 effective words/s\n",
            "INFO - 09:58:48: EPOCH 13 - PROGRESS: at 5.89% examples, 124138 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:50: EPOCH 13 - PROGRESS: at 10.97% examples, 128661 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:51: EPOCH 13 - PROGRESS: at 15.01% examples, 128436 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:52: EPOCH 13 - PROGRESS: at 21.06% examples, 130354 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:53: EPOCH 13 - PROGRESS: at 26.36% examples, 129872 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:54: EPOCH 13 - PROGRESS: at 30.92% examples, 130095 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:55: EPOCH 13 - PROGRESS: at 34.74% examples, 130155 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:56: EPOCH 13 - PROGRESS: at 39.49% examples, 129571 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:57: EPOCH 13 - PROGRESS: at 45.62% examples, 129375 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:58: EPOCH 13 - PROGRESS: at 51.01% examples, 129638 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:58:59: EPOCH 13 - PROGRESS: at 57.22% examples, 129426 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:00: EPOCH 13 - PROGRESS: at 62.17% examples, 129657 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:01: EPOCH 13 - PROGRESS: at 66.22% examples, 129744 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:02: EPOCH 13 - PROGRESS: at 70.28% examples, 129790 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:03: EPOCH 13 - PROGRESS: at 73.63% examples, 129201 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:04: EPOCH 13 - PROGRESS: at 76.85% examples, 129131 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:05: EPOCH 13 - PROGRESS: at 80.64% examples, 129191 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:06: EPOCH 13 - PROGRESS: at 85.94% examples, 129179 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:07: EPOCH 13 - PROGRESS: at 91.71% examples, 129059 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:08: EPOCH 13 - PROGRESS: at 94.18% examples, 129230 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:09: EPOCH 13 - PROGRESS: at 98.89% examples, 129256 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:09: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 09:59:09: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 09:59:09: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 09:59:09: EPOCH - 13 : training on 3885672 raw words (2810042 effective words) took 21.7s, 129341 effective words/s\n",
            "INFO - 09:59:10: EPOCH 14 - PROGRESS: at 5.89% examples, 124790 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:11: EPOCH 14 - PROGRESS: at 10.84% examples, 126188 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:12: EPOCH 14 - PROGRESS: at 14.47% examples, 126848 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:13: EPOCH 14 - PROGRESS: at 21.06% examples, 129140 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:14: EPOCH 14 - PROGRESS: at 26.65% examples, 129550 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:15: EPOCH 14 - PROGRESS: at 31.09% examples, 130233 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:16: EPOCH 14 - PROGRESS: at 35.58% examples, 130000 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:17: EPOCH 14 - PROGRESS: at 40.53% examples, 129524 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:18: EPOCH 14 - PROGRESS: at 46.09% examples, 129055 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:20: EPOCH 14 - PROGRESS: at 51.24% examples, 129013 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:21: EPOCH 14 - PROGRESS: at 57.75% examples, 128568 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:22: EPOCH 14 - PROGRESS: at 62.47% examples, 128620 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:23: EPOCH 14 - PROGRESS: at 66.22% examples, 128534 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:24: EPOCH 14 - PROGRESS: at 70.04% examples, 128372 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:25: EPOCH 14 - PROGRESS: at 73.61% examples, 128018 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:26: EPOCH 14 - PROGRESS: at 76.70% examples, 127708 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:27: EPOCH 14 - PROGRESS: at 80.42% examples, 127701 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:28: EPOCH 14 - PROGRESS: at 85.58% examples, 127502 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:29: EPOCH 14 - PROGRESS: at 91.52% examples, 127631 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:30: EPOCH 14 - PROGRESS: at 94.04% examples, 127951 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:31: EPOCH 14 - PROGRESS: at 98.54% examples, 127951 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:31: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 09:59:31: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 09:59:31: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 09:59:31: EPOCH - 14 : training on 3885672 raw words (2809746 effective words) took 21.9s, 128087 effective words/s\n",
            "INFO - 09:59:32: EPOCH 15 - PROGRESS: at 5.65% examples, 120830 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:33: EPOCH 15 - PROGRESS: at 10.70% examples, 125054 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:34: EPOCH 15 - PROGRESS: at 14.47% examples, 126496 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:35: EPOCH 15 - PROGRESS: at 21.00% examples, 127836 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:36: EPOCH 15 - PROGRESS: at 26.10% examples, 128137 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:37: EPOCH 15 - PROGRESS: at 30.80% examples, 128265 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:38: EPOCH 15 - PROGRESS: at 34.19% examples, 128029 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:39: EPOCH 15 - PROGRESS: at 38.98% examples, 127628 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:40: EPOCH 15 - PROGRESS: at 44.96% examples, 127076 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:41: EPOCH 15 - PROGRESS: at 49.52% examples, 127546 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:42: EPOCH 15 - PROGRESS: at 56.48% examples, 127702 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:43: EPOCH 15 - PROGRESS: at 61.74% examples, 128085 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:45: EPOCH 15 - PROGRESS: at 65.90% examples, 127840 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:46: EPOCH 15 - PROGRESS: at 69.60% examples, 127805 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:47: EPOCH 15 - PROGRESS: at 73.55% examples, 127578 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:48: EPOCH 15 - PROGRESS: at 76.22% examples, 127431 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:49: EPOCH 15 - PROGRESS: at 79.99% examples, 127582 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:50: EPOCH 15 - PROGRESS: at 84.34% examples, 127552 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:51: EPOCH 15 - PROGRESS: at 90.01% examples, 127390 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:52: EPOCH 15 - PROGRESS: at 93.81% examples, 127807 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:53: EPOCH 15 - PROGRESS: at 97.70% examples, 127769 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:53: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 09:59:53: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 09:59:53: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 09:59:53: EPOCH - 15 : training on 3885672 raw words (2809441 effective words) took 22.0s, 127894 effective words/s\n",
            "INFO - 09:59:54: EPOCH 16 - PROGRESS: at 5.65% examples, 121792 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:55: EPOCH 16 - PROGRESS: at 10.70% examples, 125045 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:56: EPOCH 16 - PROGRESS: at 14.10% examples, 124934 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:57: EPOCH 16 - PROGRESS: at 20.95% examples, 127483 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:58: EPOCH 16 - PROGRESS: at 25.89% examples, 127395 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 09:59:59: EPOCH 16 - PROGRESS: at 30.56% examples, 126284 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:00: EPOCH 16 - PROGRESS: at 33.34% examples, 126832 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:01: EPOCH 16 - PROGRESS: at 38.31% examples, 126358 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:02: EPOCH 16 - PROGRESS: at 43.92% examples, 126642 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:03: EPOCH 16 - PROGRESS: at 48.86% examples, 126381 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:04: EPOCH 16 - PROGRESS: at 55.12% examples, 126535 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:05: EPOCH 16 - PROGRESS: at 61.22% examples, 126948 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:06: EPOCH 16 - PROGRESS: at 65.42% examples, 127257 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:07: EPOCH 16 - PROGRESS: at 69.33% examples, 127120 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:08: EPOCH 16 - PROGRESS: at 73.54% examples, 127085 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:10: EPOCH 16 - PROGRESS: at 76.06% examples, 127039 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:11: EPOCH 16 - PROGRESS: at 79.64% examples, 126725 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:12: EPOCH 16 - PROGRESS: at 84.05% examples, 126814 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:13: EPOCH 16 - PROGRESS: at 90.01% examples, 126833 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:14: EPOCH 16 - PROGRESS: at 93.63% examples, 127184 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:15: EPOCH 16 - PROGRESS: at 97.53% examples, 127291 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:15: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 10:00:15: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 10:00:15: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 10:00:15: EPOCH - 16 : training on 3885672 raw words (2809525 effective words) took 22.0s, 127460 effective words/s\n",
            "INFO - 10:00:16: EPOCH 17 - PROGRESS: at 5.89% examples, 126287 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:17: EPOCH 17 - PROGRESS: at 10.84% examples, 126252 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:18: EPOCH 17 - PROGRESS: at 15.01% examples, 128310 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:19: EPOCH 17 - PROGRESS: at 21.06% examples, 129607 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:20: EPOCH 17 - PROGRESS: at 26.65% examples, 130559 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:21: EPOCH 17 - PROGRESS: at 31.00% examples, 130816 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:22: EPOCH 17 - PROGRESS: at 35.21% examples, 130068 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:23: EPOCH 17 - PROGRESS: at 40.11% examples, 129930 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:24: EPOCH 17 - PROGRESS: at 45.89% examples, 129852 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:25: EPOCH 17 - PROGRESS: at 51.01% examples, 130056 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:26: EPOCH 17 - PROGRESS: at 57.22% examples, 129775 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:27: EPOCH 17 - PROGRESS: at 62.17% examples, 129531 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:28: EPOCH 17 - PROGRESS: at 66.00% examples, 129276 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:30: EPOCH 17 - PROGRESS: at 70.04% examples, 129130 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:31: EPOCH 17 - PROGRESS: at 73.61% examples, 128529 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:32: EPOCH 17 - PROGRESS: at 76.85% examples, 128488 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:33: EPOCH 17 - PROGRESS: at 80.64% examples, 128597 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:34: EPOCH 17 - PROGRESS: at 85.94% examples, 128505 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:35: EPOCH 17 - PROGRESS: at 91.52% examples, 128135 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:36: EPOCH 17 - PROGRESS: at 94.04% examples, 128549 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:37: EPOCH 17 - PROGRESS: at 98.33% examples, 128368 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:37: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 10:00:37: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 10:00:37: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 10:00:37: EPOCH - 17 : training on 3885672 raw words (2810558 effective words) took 21.9s, 128603 effective words/s\n",
            "INFO - 10:00:38: EPOCH 18 - PROGRESS: at 5.65% examples, 122227 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:39: EPOCH 18 - PROGRESS: at 10.84% examples, 129445 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:40: EPOCH 18 - PROGRESS: at 14.47% examples, 128749 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:41: EPOCH 18 - PROGRESS: at 20.95% examples, 129769 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:42: EPOCH 18 - PROGRESS: at 25.89% examples, 128715 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:43: EPOCH 18 - PROGRESS: at 30.68% examples, 128823 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:44: EPOCH 18 - PROGRESS: at 33.71% examples, 128749 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:45: EPOCH 18 - PROGRESS: at 38.61% examples, 128628 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:46: EPOCH 18 - PROGRESS: at 44.96% examples, 128088 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:47: EPOCH 18 - PROGRESS: at 49.03% examples, 127196 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:48: EPOCH 18 - PROGRESS: at 55.45% examples, 127064 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:49: EPOCH 18 - PROGRESS: at 61.22% examples, 127139 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:50: EPOCH 18 - PROGRESS: at 65.26% examples, 127350 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:51: EPOCH 18 - PROGRESS: at 69.33% examples, 127689 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:52: EPOCH 18 - PROGRESS: at 73.54% examples, 127323 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:53: EPOCH 18 - PROGRESS: at 76.06% examples, 127238 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:54: EPOCH 18 - PROGRESS: at 79.64% examples, 127123 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:56: EPOCH 18 - PROGRESS: at 84.05% examples, 127010 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:57: EPOCH 18 - PROGRESS: at 90.01% examples, 127118 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:58: EPOCH 18 - PROGRESS: at 93.63% examples, 127340 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:59: EPOCH 18 - PROGRESS: at 97.53% examples, 127318 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:00:59: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 10:00:59: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 10:00:59: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 10:00:59: EPOCH - 18 : training on 3885672 raw words (2810376 effective words) took 22.1s, 127447 effective words/s\n",
            "INFO - 10:01:00: EPOCH 19 - PROGRESS: at 5.89% examples, 127951 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:01: EPOCH 19 - PROGRESS: at 10.84% examples, 129227 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:02: EPOCH 19 - PROGRESS: at 14.47% examples, 129126 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:03: EPOCH 19 - PROGRESS: at 21.00% examples, 130505 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:04: EPOCH 19 - PROGRESS: at 26.10% examples, 130192 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:05: EPOCH 19 - PROGRESS: at 30.80% examples, 130321 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:06: EPOCH 19 - PROGRESS: at 34.19% examples, 130154 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:07: EPOCH 19 - PROGRESS: at 38.61% examples, 129318 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:08: EPOCH 19 - PROGRESS: at 44.96% examples, 128818 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:09: EPOCH 19 - PROGRESS: at 49.52% examples, 129183 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:10: EPOCH 19 - PROGRESS: at 55.84% examples, 128544 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:11: EPOCH 19 - PROGRESS: at 61.47% examples, 129014 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:12: EPOCH 19 - PROGRESS: at 65.61% examples, 128606 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:13: EPOCH 19 - PROGRESS: at 69.60% examples, 128844 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:14: EPOCH 19 - PROGRESS: at 73.55% examples, 128326 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:15: EPOCH 19 - PROGRESS: at 76.46% examples, 128228 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:17: EPOCH 19 - PROGRESS: at 80.21% examples, 128052 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:18: EPOCH 19 - PROGRESS: at 84.64% examples, 127924 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:19: EPOCH 19 - PROGRESS: at 90.75% examples, 127973 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:20: EPOCH 19 - PROGRESS: at 93.91% examples, 128196 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:21: EPOCH 19 - PROGRESS: at 98.33% examples, 128294 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:21: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 10:01:21: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 10:01:21: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 10:01:21: EPOCH - 19 : training on 3885672 raw words (2809781 effective words) took 21.9s, 128301 effective words/s\n",
            "INFO - 10:01:22: EPOCH 20 - PROGRESS: at 5.89% examples, 127665 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:23: EPOCH 20 - PROGRESS: at 10.97% examples, 130621 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:24: EPOCH 20 - PROGRESS: at 15.01% examples, 129148 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:25: EPOCH 20 - PROGRESS: at 21.06% examples, 129897 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:26: EPOCH 20 - PROGRESS: at 26.36% examples, 129022 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:27: EPOCH 20 - PROGRESS: at 30.92% examples, 128826 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:28: EPOCH 20 - PROGRESS: at 34.74% examples, 129158 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:29: EPOCH 20 - PROGRESS: at 39.49% examples, 129326 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:30: EPOCH 20 - PROGRESS: at 45.62% examples, 129123 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:31: EPOCH 20 - PROGRESS: at 50.39% examples, 129162 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:32: EPOCH 20 - PROGRESS: at 56.81% examples, 128957 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:33: EPOCH 20 - PROGRESS: at 61.74% examples, 128796 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:34: EPOCH 20 - PROGRESS: at 65.90% examples, 128556 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:35: EPOCH 20 - PROGRESS: at 69.74% examples, 128728 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:36: EPOCH 20 - PROGRESS: at 73.60% examples, 128460 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:37: EPOCH 20 - PROGRESS: at 76.70% examples, 128474 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:38: EPOCH 20 - PROGRESS: at 80.42% examples, 128511 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:39: EPOCH 20 - PROGRESS: at 85.58% examples, 128565 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:40: EPOCH 20 - PROGRESS: at 90.75% examples, 128349 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:41: EPOCH 20 - PROGRESS: at 93.91% examples, 128719 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:42: EPOCH 20 - PROGRESS: at 98.33% examples, 128753 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:43: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 10:01:43: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 10:01:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 10:01:43: EPOCH - 20 : training on 3885672 raw words (2810207 effective words) took 21.8s, 128909 effective words/s\n",
            "INFO - 10:01:44: EPOCH 21 - PROGRESS: at 5.89% examples, 126291 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:45: EPOCH 21 - PROGRESS: at 10.84% examples, 128367 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:46: EPOCH 21 - PROGRESS: at 15.01% examples, 129490 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:47: EPOCH 21 - PROGRESS: at 21.10% examples, 131699 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:48: EPOCH 21 - PROGRESS: at 26.88% examples, 132137 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:49: EPOCH 21 - PROGRESS: at 31.16% examples, 132187 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:50: EPOCH 21 - PROGRESS: at 35.83% examples, 132105 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:51: EPOCH 21 - PROGRESS: at 40.72% examples, 131497 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:52: EPOCH 21 - PROGRESS: at 46.09% examples, 130265 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:53: EPOCH 21 - PROGRESS: at 51.24% examples, 130002 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:54: EPOCH 21 - PROGRESS: at 57.22% examples, 129149 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:55: EPOCH 21 - PROGRESS: at 62.47% examples, 129535 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:56: EPOCH 21 - PROGRESS: at 66.22% examples, 129260 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:57: EPOCH 21 - PROGRESS: at 70.28% examples, 129460 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:58: EPOCH 21 - PROGRESS: at 73.61% examples, 128592 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:01:59: EPOCH 21 - PROGRESS: at 76.85% examples, 128421 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:00: EPOCH 21 - PROGRESS: at 80.82% examples, 128779 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:01: EPOCH 21 - PROGRESS: at 85.94% examples, 128478 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:02: EPOCH 21 - PROGRESS: at 91.52% examples, 128299 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:03: EPOCH 21 - PROGRESS: at 94.18% examples, 128733 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:04: EPOCH 21 - PROGRESS: at 98.89% examples, 128986 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:05: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 10:02:05: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 10:02:05: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 10:02:05: EPOCH - 21 : training on 3885672 raw words (2809767 effective words) took 21.8s, 129048 effective words/s\n",
            "INFO - 10:02:06: EPOCH 22 - PROGRESS: at 5.65% examples, 122672 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:07: EPOCH 22 - PROGRESS: at 10.84% examples, 127383 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:08: EPOCH 22 - PROGRESS: at 14.47% examples, 126167 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:09: EPOCH 22 - PROGRESS: at 21.00% examples, 128534 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:10: EPOCH 22 - PROGRESS: at 26.36% examples, 129048 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:11: EPOCH 22 - PROGRESS: at 31.00% examples, 130170 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:12: EPOCH 22 - PROGRESS: at 35.21% examples, 130210 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:13: EPOCH 22 - PROGRESS: at 40.11% examples, 130303 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:14: EPOCH 22 - PROGRESS: at 45.89% examples, 129606 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:15: EPOCH 22 - PROGRESS: at 51.01% examples, 129442 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:16: EPOCH 22 - PROGRESS: at 57.22% examples, 129418 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:17: EPOCH 22 - PROGRESS: at 62.17% examples, 129551 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:18: EPOCH 22 - PROGRESS: at 66.00% examples, 129493 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:19: EPOCH 22 - PROGRESS: at 70.04% examples, 129370 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:20: EPOCH 22 - PROGRESS: at 73.60% examples, 128663 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:21: EPOCH 22 - PROGRESS: at 76.46% examples, 128297 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:22: EPOCH 22 - PROGRESS: at 80.21% examples, 128201 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:23: EPOCH 22 - PROGRESS: at 84.34% examples, 127918 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:24: EPOCH 22 - PROGRESS: at 90.01% examples, 127725 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:25: EPOCH 22 - PROGRESS: at 93.63% examples, 127851 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:26: EPOCH 22 - PROGRESS: at 97.53% examples, 127942 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:26: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 10:02:26: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 10:02:27: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 10:02:27: EPOCH - 22 : training on 3885672 raw words (2809476 effective words) took 21.9s, 128077 effective words/s\n",
            "INFO - 10:02:28: EPOCH 23 - PROGRESS: at 5.89% examples, 122722 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:29: EPOCH 23 - PROGRESS: at 10.84% examples, 124795 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:30: EPOCH 23 - PROGRESS: at 14.47% examples, 126175 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:31: EPOCH 23 - PROGRESS: at 21.06% examples, 129207 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:32: EPOCH 23 - PROGRESS: at 26.36% examples, 129296 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:33: EPOCH 23 - PROGRESS: at 30.92% examples, 129412 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:34: EPOCH 23 - PROGRESS: at 34.74% examples, 129560 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:35: EPOCH 23 - PROGRESS: at 38.98% examples, 128283 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:36: EPOCH 23 - PROGRESS: at 45.28% examples, 127924 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:37: EPOCH 23 - PROGRESS: at 49.52% examples, 128113 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:38: EPOCH 23 - PROGRESS: at 56.81% examples, 128404 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:39: EPOCH 23 - PROGRESS: at 62.17% examples, 128969 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:40: EPOCH 23 - PROGRESS: at 66.00% examples, 128629 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:41: EPOCH 23 - PROGRESS: at 70.04% examples, 128710 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:42: EPOCH 23 - PROGRESS: at 73.61% examples, 128515 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:43: EPOCH 23 - PROGRESS: at 76.70% examples, 128084 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:44: EPOCH 23 - PROGRESS: at 80.64% examples, 128412 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:45: EPOCH 23 - PROGRESS: at 85.94% examples, 128302 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:46: EPOCH 23 - PROGRESS: at 91.52% examples, 128144 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:47: EPOCH 23 - PROGRESS: at 94.04% examples, 128631 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:48: EPOCH 23 - PROGRESS: at 98.33% examples, 128511 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:48: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 10:02:48: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 10:02:48: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 10:02:48: EPOCH - 23 : training on 3885672 raw words (2809603 effective words) took 21.8s, 128612 effective words/s\n",
            "INFO - 10:02:49: EPOCH 24 - PROGRESS: at 5.89% examples, 128007 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:50: EPOCH 24 - PROGRESS: at 10.84% examples, 129557 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:51: EPOCH 24 - PROGRESS: at 15.01% examples, 130160 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:52: EPOCH 24 - PROGRESS: at 21.06% examples, 131221 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:53: EPOCH 24 - PROGRESS: at 26.65% examples, 131417 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:55: EPOCH 24 - PROGRESS: at 31.09% examples, 131692 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:56: EPOCH 24 - PROGRESS: at 35.58% examples, 131187 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:57: EPOCH 24 - PROGRESS: at 40.72% examples, 131554 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:58: EPOCH 24 - PROGRESS: at 46.27% examples, 131179 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:02:59: EPOCH 24 - PROGRESS: at 51.53% examples, 131081 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:00: EPOCH 24 - PROGRESS: at 58.18% examples, 130765 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:01: EPOCH 24 - PROGRESS: at 62.98% examples, 130997 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:02: EPOCH 24 - PROGRESS: at 66.50% examples, 130262 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:03: EPOCH 24 - PROGRESS: at 70.61% examples, 130307 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:04: EPOCH 24 - PROGRESS: at 73.64% examples, 129674 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:05: EPOCH 24 - PROGRESS: at 76.97% examples, 129480 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:06: EPOCH 24 - PROGRESS: at 81.03% examples, 129782 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:07: EPOCH 24 - PROGRESS: at 86.30% examples, 129444 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:08: EPOCH 24 - PROGRESS: at 91.97% examples, 129369 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:09: EPOCH 24 - PROGRESS: at 94.47% examples, 129737 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:10: EPOCH 24 - PROGRESS: at 99.49% examples, 129827 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:10: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 10:03:10: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 10:03:10: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 10:03:10: EPOCH - 24 : training on 3885672 raw words (2810996 effective words) took 21.6s, 130030 effective words/s\n",
            "INFO - 10:03:11: EPOCH 25 - PROGRESS: at 5.89% examples, 126506 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:12: EPOCH 25 - PROGRESS: at 10.84% examples, 128278 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:13: EPOCH 25 - PROGRESS: at 14.47% examples, 128288 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:14: EPOCH 25 - PROGRESS: at 21.06% examples, 131295 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:15: EPOCH 25 - PROGRESS: at 26.36% examples, 130542 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:16: EPOCH 25 - PROGRESS: at 30.92% examples, 130278 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:17: EPOCH 25 - PROGRESS: at 34.74% examples, 130079 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:18: EPOCH 25 - PROGRESS: at 38.98% examples, 129195 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:19: EPOCH 25 - PROGRESS: at 45.28% examples, 129061 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:20: EPOCH 25 - PROGRESS: at 50.39% examples, 129500 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:21: EPOCH 25 - PROGRESS: at 57.22% examples, 129731 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:22: EPOCH 25 - PROGRESS: at 62.17% examples, 129988 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:23: EPOCH 25 - PROGRESS: at 66.00% examples, 129636 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:24: EPOCH 25 - PROGRESS: at 70.04% examples, 129775 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:25: EPOCH 25 - PROGRESS: at 73.61% examples, 129130 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:26: EPOCH 25 - PROGRESS: at 76.70% examples, 128966 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:27: EPOCH 25 - PROGRESS: at 80.42% examples, 129025 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:28: EPOCH 25 - PROGRESS: at 85.58% examples, 128880 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:29: EPOCH 25 - PROGRESS: at 90.75% examples, 128702 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:30: EPOCH 25 - PROGRESS: at 93.91% examples, 129004 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:31: EPOCH 25 - PROGRESS: at 98.33% examples, 128980 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:32: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 10:03:32: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 10:03:32: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 10:03:32: EPOCH - 25 : training on 3885672 raw words (2809946 effective words) took 21.7s, 129239 effective words/s\n",
            "INFO - 10:03:33: EPOCH 26 - PROGRESS: at 5.89% examples, 126039 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:34: EPOCH 26 - PROGRESS: at 10.84% examples, 128259 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:35: EPOCH 26 - PROGRESS: at 14.47% examples, 128382 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:36: EPOCH 26 - PROGRESS: at 21.06% examples, 130753 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:37: EPOCH 26 - PROGRESS: at 26.10% examples, 128967 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:38: EPOCH 26 - PROGRESS: at 30.80% examples, 128806 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:39: EPOCH 26 - PROGRESS: at 34.19% examples, 128985 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:40: EPOCH 26 - PROGRESS: at 37.46% examples, 123382 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:41: EPOCH 26 - PROGRESS: at 41.84% examples, 120991 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:42: EPOCH 26 - PROGRESS: at 46.51% examples, 119008 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:43: EPOCH 26 - PROGRESS: at 50.39% examples, 117252 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:44: EPOCH 26 - PROGRESS: at 55.12% examples, 116031 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:45: EPOCH 26 - PROGRESS: at 61.05% examples, 117116 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:46: EPOCH 26 - PROGRESS: at 65.13% examples, 117698 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:47: EPOCH 26 - PROGRESS: at 68.93% examples, 118140 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:48: EPOCH 26 - PROGRESS: at 73.52% examples, 118622 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:49: EPOCH 26 - PROGRESS: at 75.86% examples, 118976 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:50: EPOCH 26 - PROGRESS: at 78.69% examples, 119416 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:51: EPOCH 26 - PROGRESS: at 83.51% examples, 119955 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:52: EPOCH 26 - PROGRESS: at 89.63% examples, 120057 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:53: EPOCH 26 - PROGRESS: at 93.35% examples, 120627 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:54: EPOCH 26 - PROGRESS: at 96.96% examples, 121251 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:55: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 10:03:55: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 10:03:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 10:03:55: EPOCH - 26 : training on 3885672 raw words (2810238 effective words) took 23.1s, 121627 effective words/s\n",
            "INFO - 10:03:56: EPOCH 27 - PROGRESS: at 5.89% examples, 124712 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:57: EPOCH 27 - PROGRESS: at 10.84% examples, 126361 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:58: EPOCH 27 - PROGRESS: at 15.01% examples, 129570 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:03:59: EPOCH 27 - PROGRESS: at 21.10% examples, 131487 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:00: EPOCH 27 - PROGRESS: at 26.65% examples, 130480 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:01: EPOCH 27 - PROGRESS: at 31.00% examples, 129832 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:02: EPOCH 27 - PROGRESS: at 34.74% examples, 129026 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:03: EPOCH 27 - PROGRESS: at 40.11% examples, 129352 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:04: EPOCH 27 - PROGRESS: at 45.89% examples, 129124 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:05: EPOCH 27 - PROGRESS: at 51.01% examples, 129187 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:06: EPOCH 27 - PROGRESS: at 57.22% examples, 129048 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:07: EPOCH 27 - PROGRESS: at 62.17% examples, 129072 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:08: EPOCH 27 - PROGRESS: at 66.00% examples, 128916 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:09: EPOCH 27 - PROGRESS: at 69.74% examples, 128676 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:10: EPOCH 27 - PROGRESS: at 73.56% examples, 128491 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:11: EPOCH 27 - PROGRESS: at 76.70% examples, 128649 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:12: EPOCH 27 - PROGRESS: at 80.42% examples, 128370 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:13: EPOCH 27 - PROGRESS: at 85.58% examples, 128187 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:14: EPOCH 27 - PROGRESS: at 91.52% examples, 128251 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:15: EPOCH 27 - PROGRESS: at 94.04% examples, 128531 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:16: EPOCH 27 - PROGRESS: at 98.33% examples, 128437 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:17: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 10:04:17: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 10:04:17: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 10:04:17: EPOCH - 27 : training on 3885672 raw words (2809231 effective words) took 21.9s, 128546 effective words/s\n",
            "INFO - 10:04:18: EPOCH 28 - PROGRESS: at 5.89% examples, 128075 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:19: EPOCH 28 - PROGRESS: at 10.84% examples, 129125 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:20: EPOCH 28 - PROGRESS: at 14.47% examples, 128411 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:21: EPOCH 28 - PROGRESS: at 21.06% examples, 130847 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:22: EPOCH 28 - PROGRESS: at 26.36% examples, 130449 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:23: EPOCH 28 - PROGRESS: at 30.92% examples, 130519 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:24: EPOCH 28 - PROGRESS: at 35.21% examples, 131006 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:25: EPOCH 28 - PROGRESS: at 40.11% examples, 130156 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:26: EPOCH 28 - PROGRESS: at 45.89% examples, 129642 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:27: EPOCH 28 - PROGRESS: at 51.01% examples, 129702 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:28: EPOCH 28 - PROGRESS: at 57.22% examples, 129372 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:29: EPOCH 28 - PROGRESS: at 62.47% examples, 129566 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:30: EPOCH 28 - PROGRESS: at 66.22% examples, 129292 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:31: EPOCH 28 - PROGRESS: at 70.28% examples, 129460 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:32: EPOCH 28 - PROGRESS: at 73.61% examples, 128729 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:33: EPOCH 28 - PROGRESS: at 76.85% examples, 128627 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:34: EPOCH 28 - PROGRESS: at 80.64% examples, 128621 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:35: EPOCH 28 - PROGRESS: at 85.58% examples, 128346 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:36: EPOCH 28 - PROGRESS: at 90.75% examples, 128190 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:37: EPOCH 28 - PROGRESS: at 93.91% examples, 128606 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:38: EPOCH 28 - PROGRESS: at 97.94% examples, 128374 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:39: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 10:04:39: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 10:04:39: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 10:04:39: EPOCH - 28 : training on 3885672 raw words (2810551 effective words) took 21.9s, 128556 effective words/s\n",
            "INFO - 10:04:40: EPOCH 29 - PROGRESS: at 5.89% examples, 125835 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:41: EPOCH 29 - PROGRESS: at 10.97% examples, 129112 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:42: EPOCH 29 - PROGRESS: at 15.01% examples, 128081 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:43: EPOCH 29 - PROGRESS: at 21.06% examples, 129424 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:44: EPOCH 29 - PROGRESS: at 26.36% examples, 129491 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:45: EPOCH 29 - PROGRESS: at 30.92% examples, 129049 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:46: EPOCH 29 - PROGRESS: at 34.74% examples, 129256 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:47: EPOCH 29 - PROGRESS: at 39.49% examples, 128654 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:48: EPOCH 29 - PROGRESS: at 45.62% examples, 128126 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:49: EPOCH 29 - PROGRESS: at 50.39% examples, 128384 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:50: EPOCH 29 - PROGRESS: at 56.81% examples, 128147 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:51: EPOCH 29 - PROGRESS: at 61.74% examples, 128367 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:52: EPOCH 29 - PROGRESS: at 65.90% examples, 128112 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:53: EPOCH 29 - PROGRESS: at 69.74% examples, 128054 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:54: EPOCH 29 - PROGRESS: at 73.55% examples, 127419 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:55: EPOCH 29 - PROGRESS: at 76.46% examples, 127434 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:56: EPOCH 29 - PROGRESS: at 80.21% examples, 127544 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:57: EPOCH 29 - PROGRESS: at 85.58% examples, 127822 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:58: EPOCH 29 - PROGRESS: at 91.52% examples, 127895 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:04:59: EPOCH 29 - PROGRESS: at 94.04% examples, 128049 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:00: EPOCH 29 - PROGRESS: at 98.54% examples, 128308 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:00: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 10:05:00: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 10:05:00: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 10:05:00: EPOCH - 29 : training on 3885672 raw words (2810809 effective words) took 21.9s, 128413 effective words/s\n",
            "INFO - 10:05:02: EPOCH 30 - PROGRESS: at 5.65% examples, 120407 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:03: EPOCH 30 - PROGRESS: at 10.70% examples, 123574 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:04: EPOCH 30 - PROGRESS: at 14.47% examples, 125480 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:05: EPOCH 30 - PROGRESS: at 21.00% examples, 126976 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:06: EPOCH 30 - PROGRESS: at 26.10% examples, 126299 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:07: EPOCH 30 - PROGRESS: at 30.80% examples, 126818 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:08: EPOCH 30 - PROGRESS: at 34.19% examples, 127042 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:09: EPOCH 30 - PROGRESS: at 38.98% examples, 127032 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:10: EPOCH 30 - PROGRESS: at 45.62% examples, 127484 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:11: EPOCH 30 - PROGRESS: at 50.39% examples, 127873 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:12: EPOCH 30 - PROGRESS: at 56.81% examples, 127500 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:13: EPOCH 30 - PROGRESS: at 61.74% examples, 127740 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:14: EPOCH 30 - PROGRESS: at 66.00% examples, 128095 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:15: EPOCH 30 - PROGRESS: at 70.04% examples, 128158 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:16: EPOCH 30 - PROGRESS: at 73.61% examples, 127890 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:17: EPOCH 30 - PROGRESS: at 76.70% examples, 127780 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:18: EPOCH 30 - PROGRESS: at 80.42% examples, 127648 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:19: EPOCH 30 - PROGRESS: at 84.64% examples, 127342 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:20: EPOCH 30 - PROGRESS: at 90.17% examples, 127229 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:21: EPOCH 30 - PROGRESS: at 93.81% examples, 127657 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:22: EPOCH 30 - PROGRESS: at 97.94% examples, 127779 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 10:05:22: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 10:05:22: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 10:05:22: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 10:05:22: EPOCH - 30 : training on 3885672 raw words (2810842 effective words) took 22.0s, 128001 effective words/s\n",
            "INFO - 10:05:22: training on a 116570160 raw words (84302431 effective words) took 660.0s, 127724 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to train the model: 11.0 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mm8xo_Uazax",
        "colab_type": "code",
        "outputId": "72877c27-8e69-4fc9-b2dd-5214422c3bee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Save the model\n",
        "w2v_model.wv.save_word2vec_format('w2v_model.bin')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 10:05:31: storing 158119x100 projection weights into w2v_model.bin\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXzCEOKma65O",
        "colab_type": "code",
        "outputId": "b3d6dd4f-2452-4bcf-b1d0-e1304d7b4d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "w2v_model.wv.save_word2vec_format('w2v_model.txt', binary=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 10:05:44: storing 158119x100 projection weights into w2v_model.txt\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwi6Jm5JbUEx",
        "colab_type": "code",
        "outputId": "5845e0c7-0b20-4cda-fc25-f6df4d8fbc21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Total number of words vectorized\n",
        "# Notice that this number is large because we kept words with frequency 1\n",
        "words = list(w2v_model.wv.vocab)\n",
        "len(words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "158119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4ZSxP95ajtU",
        "colab_type": "text"
      },
      "source": [
        "# Most Similar Word Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngWYDz9o76CD",
        "colab_type": "code",
        "outputId": "5f86026c-902b-44ab-99a6-15a8655cde59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"fake\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 10:06:18: precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('id', 0.5883486270904541),\n",
              " ('ids', 0.5781641006469727),\n",
              " ('hoax', 0.5745216608047485),\n",
              " ('fabricate', 0.5445030927658081),\n",
              " ('whopper', 0.522573709487915),\n",
              " ('false_narrative', 0.519706666469574),\n",
              " ('false', 0.5131078958511353),\n",
              " ('crisis_actor', 0.4988062381744385),\n",
              " ('bogus', 0.4836941957473755),\n",
              " ('fake_news', 0.4749912619590759)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhDBFwCQ8GOQ",
        "colab_type": "code",
        "outputId": "faaa6b35-a22a-4aa1-b07b-b40ed29a9cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"freedom\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('liberty', 0.6756128072738647),\n",
              " ('democracy', 0.631916880607605),\n",
              " ('cherish', 0.60960853099823),\n",
              " ('freedom_speech', 0.5919955968856812),\n",
              " ('freedom_expression', 0.5844323635101318),\n",
              " ('right', 0.573498010635376),\n",
              " ('semblance', 0.5713706016540527),\n",
              " ('dignity', 0.5597898960113525),\n",
              " ('respect', 0.5502725839614868),\n",
              " ('prosperity', 0.5439368486404419)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4rL20molLa_",
        "colab_type": "code",
        "outputId": "399d7c40-d543-4a33-bdab-9e46df3e665f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"attack\"],topn=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('target', 0.6575837731361389),\n",
              " ('assault', 0.6551152467727661),\n",
              " ('terrorist_attack', 0.6341935396194458),\n",
              " ('claim', 0.6250004768371582),\n",
              " ('strike', 0.6227885484695435),\n",
              " ('kill', 0.5861219763755798),\n",
              " ('indiscriminate', 0.5814937353134155),\n",
              " ('force', 0.5803516507148743),\n",
              " ('launch', 0.5773041844367981),\n",
              " ('killing', 0.5768757462501526)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my4owghFlYGY",
        "colab_type": "code",
        "outputId": "b942c607-f483-46dc-d9ab-573b48de3072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"bomb\"],topn=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('detonate', 0.6688288450241089),\n",
              " ('bombing', 0.6180896759033203),\n",
              " ('munition', 0.5712682008743286),\n",
              " ('bombardment', 0.5458507537841797),\n",
              " ('civilian', 0.5426082611083984),\n",
              " ('attack', 0.5399023294448853),\n",
              " ('gingerly', 0.5328900814056396),\n",
              " ('atomic_bomb', 0.5309829711914062),\n",
              " ('governmentsnot', 0.5238995552062988),\n",
              " ('neardefenseless', 0.5224360227584839)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n__NsgvzlwYM",
        "colab_type": "code",
        "outputId": "551de08f-39cc-4135-906f-3c218d445b95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"president\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('elect', 0.7453252077102661),\n",
              " ('obama', 0.7041237354278564),\n",
              " ('white_house', 0.6970391273498535),\n",
              " ('presidency', 0.6857277154922485),\n",
              " ('trump', 0.6828287243843079),\n",
              " ('administration', 0.6744243502616882),\n",
              " ('elect_president', 0.6497210264205933),\n",
              " ('hillary_clinton', 0.6286641955375671),\n",
              " ('office', 0.6267598867416382),\n",
              " ('presidentelect_trump', 0.6243784427642822)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22S6-D63l5VD",
        "colab_type": "code",
        "outputId": "40f86995-2029-47f1-9ea4-620ed4880ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"terror\"],topn=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('terrorism', 0.6181561946868896),\n",
              " ('terrorist', 0.6153697967529297),\n",
              " ('islamism', 0.5353000164031982),\n",
              " ('kla', 0.5323553681373596),\n",
              " ('extremism', 0.5294589996337891),\n",
              " ('terror_group', 0.529383659362793),\n",
              " ('terror_attack', 0.5037004351615906),\n",
              " ('islamic', 0.4970577657222748),\n",
              " ('jihadist', 0.4927752912044525),\n",
              " ('terrorist_attack', 0.4899193346500397)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4f71VS5e62e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can see from above that word vector learnt are good estimates for understanding relation between words"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}